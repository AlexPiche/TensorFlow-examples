{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://jmetzen.github.io/2015-11-27/vae.html\n",
    "# https://home.zhaw.ch/~dueo/bbs/files/vae.pdf\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(0)\n",
    "tf.set_random_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "n_samples = mnist.train.num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_shape = 784\n",
    "n_hidden = 250\n",
    "output_shape = 20 # 10-D Gaussian\n",
    "\n",
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "W1_enc = weight_variable([input_shape, n_hidden])\n",
    "b1_enc = bias_variable([n_hidden])\n",
    "    \n",
    "W2_enc_mean = weight_variable([n_hidden, output_shape/2])\n",
    "b2_enc_mean = bias_variable([output_shape/2])\n",
    "\n",
    "W2_enc_log_sd = weight_variable([n_hidden, output_shape/2])\n",
    "b2_enc_log_sd = bias_variable([output_shape/2])\n",
    "   \n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "x2 = tf.nn.softplus(tf.matmul(x, W1_enc) + b1_enc)\n",
    "z_mean = tf.matmul(x2, W2_enc_mean) + b2_enc_mean # 5-D gaussian\n",
    "z_log_sd2 = tf.matmul(x2, W2_enc_log_sd) + b2_enc_log_sd\n",
    "\n",
    "eps = tf.random_normal(shape=[output_shape/2])\n",
    "\n",
    "z = z_mean + tf.exp(z_log_sd2) * eps\n",
    "\n",
    "W_dec = weight_variable([output_shape/2, n_hidden])\n",
    "b_dec = bias_variable([n_hidden])\n",
    "\n",
    "W1_dec = weight_variable([n_hidden, n_hidden])\n",
    "b1_dec = bias_variable([n_hidden])\n",
    "    \n",
    "W2_dec = weight_variable([n_hidden, input_shape])\n",
    "b2_dec = bias_variable([input_shape])\n",
    "\n",
    "z1 = tf.nn.softplus(tf.matmul(z, W_dec) + b_dec)\n",
    "z2 = tf.nn.softplus(tf.matmul(z1, W1_dec) + b1_dec)\n",
    "x_hat = tf.nn.sigmoid(tf.matmul(z2, W2_dec) + b2_dec)\n",
    "\n",
    "latent_loss = -0.5 * tf.reduce_sum(1 + z_log_sd2 - tf.square(z_mean) - tf.exp(z_log_sd2), 1)\n",
    "\n",
    "reconstruction_loss = -tf.reduce_sum(x * tf.log(1e-10 + x_hat) + (1-x) * tf.log(1e-10 + 1 - x_hat), 1)\n",
    "\n",
    "loss = tf.reduce_mean(latent_loss + reconstruction_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch:', '0001', 'cost=', '183.728795582')\n",
      "('Epoch:', '0006', 'cost=', '111.212459689')\n",
      "('Epoch:', '0011', 'cost=', '104.032178289')\n",
      "('Epoch:', '0016', 'cost=', '100.183120367')\n",
      "('Epoch:', '0021', 'cost=', '98.345527469')\n",
      "('Epoch:', '0026', 'cost=', '96.809511691')\n",
      "('Epoch:', '0031', 'cost=', '96.009689900')\n",
      "('Epoch:', '0036', 'cost=', '95.097560466')\n",
      "('Epoch:', '0041', 'cost=', '94.294942766')\n",
      "('Epoch:', '0046', 'cost=', '93.962665683')\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "train_step = tf.train.AdamOptimizer(0.001).minimize(loss)\n",
    "training_epochs = 50\n",
    "display_step = 5\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(n_samples / batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch = mnist.train.next_batch(batch_size)\n",
    "            _, cost = sess.run([train_step, loss], feed_dict={x:  batch[0]})\n",
    "            avg_cost += cost / n_samples * batch_size\n",
    "            \n",
    "        # Display logs per epoch step\n",
    "        if epoch+1 % display_step == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \n",
    "                  \"cost=\", \"{:.9f}\".format(avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
